{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574f1350-8f09-4eea-8e12-ac64a1364c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pyensembl\n",
    "\n",
    "from Bio import Entrez\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "import wormbase_parasite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b60487-76db-45f4-a4c9-41c45d5b4842",
   "metadata": {},
   "source": [
    "## Download seq from ensembl (pyensembl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5bbe15-ff5c-46ee-9868-b4bea96d63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = pyensembl.EnsemblRelease(100, \"mus_musculus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772e1d7-99e1-4edf-a41e-2ac1a06d89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts\n",
    "\n",
    "Actg1_transcript = genome.transcript_by_id('ENSMUST00000071555')\n",
    "Actg1_mRNA_sequence = Actg1_transcript.sequence\n",
    "# Actg1_transcript = genome.transcript_by_id('ENSMUST00000071555.12')\n",
    "# Actg1_mRNA_sequence = Actg1_transcript.sequence\n",
    "Fermt2_transcript = genome.transcript_by_id('ENSMUST00000045905')\n",
    "Fermt2_mRNA_sequence = Fermt2_transcript.sequence\n",
    "Actb_transcript = genome.transcript_by_id('ENSMUST00000100497')\n",
    "Actb_mRNA_sequence = Actb_transcript.sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5441be8a-2296-4ea5-bafc-2af668696a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_seq_as_file(gene, folder):\n",
    "    filename = folder + gene + \".fasta\"\n",
    "    file = open(filename, 'w')\n",
    "    file.write(Actg1_mRNA_sequence)\n",
    "    file.close()\n",
    "\n",
    "folder = \"/home/ylee/blast/blastdb/\"\n",
    "gene_list = ['Actg1_mRNA_sequence', 'Fermt2_mRNA_sequence', 'Actb_mRNA_sequence']\n",
    "\n",
    "for gene in gene_list:\n",
    "    save_seq_as_file(gene, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27173a39-983b-401f-bb48-9b973e9e0145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ENSMUSE00000800321', 'ENSMUSE00001254186', 'ENSMUSE00001293379', 'ENSMUSE00001279808', 'ENSMUSE00001284007', 'ENSMUSE00000488442'] ['ENSMUSE00000706602', 'ENSMUSE00000408319', 'ENSMUSE00000315015', 'ENSMUSE00000314890', 'ENSMUSE00000314881', 'ENSMUSE00000315007', 'ENSMUSE00000314872', 'ENSMUSE00000314864', 'ENSMUSE00000314991', 'ENSMUSE00000314985', 'ENSMUSE00000314978', 'ENSMUSE00000314969', 'ENSMUSE00000314959', 'ENSMUSE00000314950', 'ENSMUSE00000336558'] ['ENSMUSE00000877175', 'ENSMUSE00001309702', 'ENSMUSE00001272130', 'ENSMUSE00000517504', 'ENSMUSE00000534432', 'ENSMUSE00000879080']\n"
     ]
    }
   ],
   "source": [
    "# exons in transcripts\n",
    "\n",
    "Actg1_exon = genome.exon_ids_of_transcript_id('ENSMUST00000071555')     # 6 exons\n",
    "Ferm2_exon = genome.exon_ids_of_transcript_id('ENSMUST00000045905')     # 15 exons\n",
    "Actb_exon = genome.exon_ids_of_transcript_id('ENSMUST00000100497')      # 6 exons\n",
    "\n",
    "print(Actg1_exon, Ferm2_exon, Actb_exon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b441398-1cf6-4f8c-b691-8c03d6a356c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download seq from NCBI (bio.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de2ab7c-984f-4b85-b90f-4a362eaf841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actg1, Fermt2, Actb mRNA identifiers\n",
    "ensembl_transcript_ids = [\n",
    "    'ENSMUST00000071555',\n",
    "    'ENSMUST00000045905',\n",
    "    'ENSMUST00000100497'\n",
    "]\n",
    "NCBI_transcript_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7326d3ae-652b-4e25-8cc1-bdb4b9fc50f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCBI RefSeq IDs for ENSMUST00000071555:\n",
      "RefSeq ID: NM_009609\n",
      "NCBI RefSeq IDs for ENSMUST00000045905:\n",
      "RefSeq ID: NM_146054\n",
      "RefSeq ID: NM_001360526\n",
      "RefSeq ID: NM_001360525\n",
      "NCBI RefSeq IDs for ENSMUST00000100497:\n",
      "RefSeq ID: NM_007393\n",
      "['NM_009609', 'NM_146054', 'NM_001360526', 'NM_001360525', 'NM_007393']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ensembl_transcript_ids)):\n",
    "    # API URL to look up the corresponding NCBI identifiers\n",
    "    url = f\"https://rest.ensembl.org/xrefs/id/{ensembl_transcript_ids[i]}?external_db=RefSeq_mRNA\"\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            \n",
    "            print(f\"NCBI RefSeq IDs for {ensembl_transcript_ids[i]}:\")\n",
    "            for entry in data:\n",
    "                NCBI_transcript_ids.append(entry['primary_id'])\n",
    "                print(f\"RefSeq ID: {entry['primary_id']}\")\n",
    "            \n",
    "        else:\n",
    "            NCBI_transcript_ids.append(\"No NCBI RefSeq IDs found for : \"+{ensembl_transcript_ids[i]})\n",
    "            print(f\"No NCBI RefSeq IDs found for {ensembl_transcript_ids[i]}.\")\n",
    "    else:\n",
    "        NCBI_transcript_ids.append(\"Failed to retrieve data: \"+{response.status_code})\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "\n",
    "print(NCBI_transcript_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a415a53-c9fe-49a0-bd35-9e70a69ba1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download the genbank files by NM_ transcript IDs to target folder\n",
    "\n",
    "def ncbi_downloader(query_ls, folder):  # query_ls: a list of NM_ transcript IDs \n",
    "                                        # folder: a string to specify the target folder to download\n",
    "    Entrez.email = \"yjbulee@gmail.com\"  # Always tell NCBI who you are\n",
    "    files = [file for file in os.listdir(folder)]\n",
    "    \n",
    "    for NM_ in query_ls:\n",
    "        file = NM_ + '.gb'\n",
    "        # file = NM_ + '.fasta'\n",
    "        filename = folder + file\n",
    "        print(filename)                  ################################s\n",
    "        try:\n",
    "            if file not in files:\n",
    "                # Downloading...\n",
    "                input_handle = Entrez.efetch(db=\"nucleotide\", id=NM_, rettype=\"gb\", retmode=\"text\")\n",
    "                # input_handle = Entrez.efetch(db=\"homologene\", rettype=\"fasta\", retmode=\"text\")\n",
    "                \n",
    "                out_handle = open(filename, \"w\")\n",
    "                out_handle.write(input_handle.read())\n",
    "                out_handle.close()\n",
    "                input_handle.close()\n",
    "        except:\n",
    "            print(\"Interrupted!!There are some problems when handling \"+ NM_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13bb355b-50bb-4721-8f8c-929ef11101d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ylee/blast/blastdb/NM_009609.fasta\n",
      "/home/ylee/blast/blastdb/NM_146054.fasta\n",
      "/home/ylee/blast/blastdb/NM_001360526.fasta\n",
      "/home/ylee/blast/blastdb/NM_001360525.fasta\n",
      "/home/ylee/blast/blastdb/NM_007393.fasta\n"
     ]
    }
   ],
   "source": [
    "query_ls = NCBI_transcript_ids\n",
    "folder = '/home/ylee/blast/blastdb/'     ## need to be modified\n",
    "\n",
    "ncbi_downloader(query_ls, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff9496d4-cd6f-41ca-b5ba-d9a77454d035",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package Bio.Entrez in Bio:\n",
      "\n",
      "NAME\n",
      "    Bio.Entrez - Provides code to access NCBI over the WWW.\n",
      "\n",
      "DESCRIPTION\n",
      "    The main Entrez web page is available at:\n",
      "    http://www.ncbi.nlm.nih.gov/Entrez/\n",
      "    \n",
      "    Entrez Programming Utilities web page is available at:\n",
      "    http://www.ncbi.nlm.nih.gov/books/NBK25501/\n",
      "    \n",
      "    This module provides a number of functions like ``efetch`` (short for\n",
      "    Entrez Fetch) which will return the data as a handle object. This is\n",
      "    a standard interface used in Python for reading data from a file, or\n",
      "    in this case a remote network connection, and provides methods like\n",
      "    ``.read()`` or offers iteration over the contents line by line. See\n",
      "    also \"What the heck is a handle?\" in the Biopython Tutorial and\n",
      "    Cookbook: http://biopython.org/DIST/docs/tutorial/Tutorial.html\n",
      "    http://biopython.org/DIST/docs/tutorial/Tutorial.pdf\n",
      "    The handle returned by these functions can be either in text mode or\n",
      "    in binary mode, depending on the data requested and the results\n",
      "    returned by NCBI Entrez. Typically, XML data will be in binary mode\n",
      "    while other data will be in text mode, as required by the downstream\n",
      "    parser to parse the data.\n",
      "    \n",
      "    Unlike a handle to a file on disk from the ``open(filename)`` function,\n",
      "    which has a ``.name`` attribute giving the filename, the handles from\n",
      "    ``Bio.Entrez`` all have a ``.url`` attribute instead giving the URL\n",
      "    used to connect to the NCBI Entrez API.\n",
      "    \n",
      "    All the functions that send requests to the NCBI Entrez API will\n",
      "    automatically respect the NCBI rate limit (of 3 requests per second\n",
      "    without an API key, or 10 requests per second with an API key) and\n",
      "    will automatically retry when encountering transient failures\n",
      "    (i.e. connection failures or HTTP 5XX codes). By default, Biopython\n",
      "    does a maximum of three tries before giving up, and sleeps for 15\n",
      "    seconds between tries. You can tweak these parameters by setting\n",
      "    ``Bio.Entrez.max_tries`` and ``Bio.Entrez.sleep_between_tries``.\n",
      "    \n",
      "    The Entrez module also provides an XML parser which takes a handle\n",
      "    as input.\n",
      "    \n",
      "    Variables:\n",
      "    \n",
      "        - email        Set the Entrez email parameter (default is not set).\n",
      "        - tool         Set the Entrez tool parameter (default is ``biopython``).\n",
      "        - api_key      Personal API key from NCBI. If not set, only 3 queries per\n",
      "          second are allowed. 10 queries per seconds otherwise with a\n",
      "          valid API key.\n",
      "        - max_tries    Configures how many times failed requests will be\n",
      "          automatically retried on error (default is 3).\n",
      "        - sleep_between_tries   The delay, in seconds, before retrying a request on\n",
      "          error (default is 15).\n",
      "    \n",
      "    Functions:\n",
      "    \n",
      "        - efetch       Retrieves records in the requested format from a list of one or\n",
      "          more primary IDs or from the user's environment\n",
      "        - epost        Posts a file containing a list of primary IDs for future use in\n",
      "          the user's environment to use with subsequent search strategies\n",
      "        - esearch      Searches and retrieves primary IDs (for use in EFetch, ELink,\n",
      "          and ESummary) and term translations and optionally retains\n",
      "          results for future use in the user's environment.\n",
      "        - elink        Checks for the existence of an external or Related Articles link\n",
      "          from a list of one or more primary IDs.  Retrieves primary IDs\n",
      "          and relevancy scores for links to Entrez databases or Related\n",
      "          Articles;  creates a hyperlink to the primary LinkOut provider\n",
      "          for a specific ID and database, or lists LinkOut URLs\n",
      "          and Attributes for multiple IDs.\n",
      "        - einfo        Provides field index term counts, last update, and available\n",
      "          links for each database.\n",
      "        - esummary     Retrieves document summaries from a list of primary IDs or from\n",
      "          the user's environment.\n",
      "        - egquery      Provides Entrez database counts in XML for a single search\n",
      "          using Global Query.\n",
      "        - espell       Retrieves spelling suggestions.\n",
      "        - ecitmatch    Retrieves PubMed IDs (PMIDs) that correspond to a set of\n",
      "          input citation strings.\n",
      "    \n",
      "        - read         Parses the XML results returned by any of the above functions.\n",
      "          Alternatively, the XML data can be read from a file opened in binary mode.\n",
      "          Typical usage is:\n",
      "    \n",
      "              >>> from Bio import Entrez\n",
      "              >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "              >>> handle = Entrez.einfo() # or esearch, efetch, ...\n",
      "              >>> record = Entrez.read(handle)\n",
      "              >>> handle.close()\n",
      "    \n",
      "           where record is now a Python dictionary or list.\n",
      "    \n",
      "        - parse        Parses the XML results returned by those of the above functions\n",
      "          which can return multiple records - such as efetch, esummary\n",
      "          and elink. Typical usage is:\n",
      "    \n",
      "              >>> handle = Entrez.esummary(db=\"pubmed\", id=\"19304878,14630660\", retmode=\"xml\")\n",
      "              >>> records = Entrez.parse(handle)\n",
      "              >>> for record in records:\n",
      "              ...     # each record is a Python dictionary or list.\n",
      "              ...     print(record['Title'])\n",
      "              Biopython: freely available Python tools for computational molecular biology and bioinformatics.\n",
      "              PDB file parser and structure class implemented in Python.\n",
      "              >>> handle.close()\n",
      "    \n",
      "          This function is appropriate only if the XML file contains\n",
      "          multiple records, and is particular useful for large files.\n",
      "    \n",
      "        - _open        Internally used function.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    Parser\n",
      "\n",
      "FUNCTIONS\n",
      "    ecitmatch(**keywds)\n",
      "        Retrieve PMIDs for input citation strings, returned as a handle.\n",
      "        \n",
      "        ECitMatch retrieves PubMed IDs (PMIDs) that correspond to a set of input\n",
      "        citation strings.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ECitMatch\n",
      "        \n",
      "        Return a handle to the results, by default in plain text\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> citation_1 = {\"journal_title\": \"proc natl acad sci u s a\",\n",
      "        ...               \"year\": \"1991\", \"volume\": \"88\", \"first_page\": \"3248\",\n",
      "        ...               \"author_name\": \"mann bj\", \"key\": \"citation_1\"}\n",
      "        >>> handle = Entrez.ecitmatch(db=\"pubmed\", bdata=[citation_1])\n",
      "        >>> print(handle.read().strip().split(\"|\"))\n",
      "        ['proc natl acad sci u s a', '1991', '88', '3248', 'mann bj', 'citation_1', '2014248']\n",
      "        >>> handle.close()\n",
      "    \n",
      "    efetch(db, **keywords)\n",
      "        Fetch Entrez results which are returned as a handle.\n",
      "        \n",
      "        EFetch retrieves records in the requested format from a list or set of one or\n",
      "        more UIs or from user's environment.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EFetch\n",
      "        \n",
      "        Return a handle to the results.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.efetch(db=\"nucleotide\", id=\"AY851612\", rettype=\"gb\", retmode=\"text\")\n",
      "        >>> print(handle.readline().strip())\n",
      "        LOCUS       AY851612                 892 bp    DNA     linear   PLN 10-APR-2007\n",
      "        >>> handle.close()\n",
      "        \n",
      "        This will automatically use an HTTP POST rather than HTTP GET if there\n",
      "        are over 200 identifiers as recommended by the NCBI.\n",
      "        \n",
      "        **Warning:** The NCBI changed the default retmode in Feb 2012, so many\n",
      "        databases which previously returned text output now give XML.\n",
      "    \n",
      "    egquery(**keywds)\n",
      "        Provide Entrez database counts for a global search.\n",
      "        \n",
      "        EGQuery provides Entrez database counts in XML for a single search\n",
      "        using Global Query.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EGQuery\n",
      "        \n",
      "        Return a handle to the results in XML format.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        This quick example based on a longer version from the Biopython\n",
      "        Tutorial just checks there are over 60 matches for 'Biopython'\n",
      "        in PubMedCentral:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.egquery(term=\"biopython\")\n",
      "        >>> record = Entrez.read(handle)\n",
      "        >>> handle.close()\n",
      "        >>> for row in record[\"eGQueryResult\"]:\n",
      "        ...     if \"pmc\" in row[\"DbName\"]:\n",
      "        ...         print(int(row[\"Count\"]) > 60)\n",
      "        True\n",
      "    \n",
      "    einfo(**keywds)\n",
      "        Return a summary of the Entrez databases as a results handle.\n",
      "        \n",
      "        EInfo provides field names, index term counts, last update, and\n",
      "        available links for each Entrez database.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EInfo\n",
      "        \n",
      "        Return a handle to the results, by default in XML format.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> record = Entrez.read(Entrez.einfo())\n",
      "        >>> 'pubmed' in record['DbList']\n",
      "        True\n",
      "    \n",
      "    elink(**keywds)\n",
      "        Check for linked external articles and return a handle.\n",
      "        \n",
      "        ELink checks for the existence of an external or Related Articles link\n",
      "        from a list of one or more primary IDs;  retrieves IDs and relevancy\n",
      "        scores for links to Entrez databases or Related Articles; creates a\n",
      "        hyperlink to the primary LinkOut provider for a specific ID and\n",
      "        database, or lists LinkOut URLs and attributes for multiple IDs.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ELink\n",
      "        \n",
      "        Return a handle to the results, by default in XML format.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        This example finds articles related to the Biopython application\n",
      "        note's entry in the PubMed database:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> pmid = \"19304878\"\n",
      "        >>> handle = Entrez.elink(dbfrom=\"pubmed\", id=pmid, linkname=\"pubmed_pubmed\")\n",
      "        >>> record = Entrez.read(handle)\n",
      "        >>> handle.close()\n",
      "        >>> print(record[0][\"LinkSetDb\"][0][\"LinkName\"])\n",
      "        pubmed_pubmed\n",
      "        >>> linked = [link[\"Id\"] for link in record[0][\"LinkSetDb\"][0][\"Link\"]]\n",
      "        >>> \"17121776\" in linked\n",
      "        True\n",
      "        \n",
      "        This is explained in much more detail in the Biopython Tutorial.\n",
      "    \n",
      "    epost(db, **keywds)\n",
      "        Post a file of identifiers for future use.\n",
      "        \n",
      "        Posts a file containing a list of UIs for future use in the user's\n",
      "        environment to use with subsequent search strategies.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EPost\n",
      "        \n",
      "        Return a handle to the results.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "    \n",
      "    esearch(db, term, **keywds)\n",
      "        Run an Entrez search and return a handle to the results.\n",
      "        \n",
      "        ESearch searches and retrieves primary IDs (for use in EFetch, ELink\n",
      "        and ESummary) and term translations, and optionally retains results\n",
      "        for future use in the user's environment.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch\n",
      "        \n",
      "        Return a handle to the results which are always in XML format.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.esearch(db=\"nucleotide\", retmax=10, term=\"opuntia[ORGN] accD\", idtype=\"acc\")\n",
      "        >>> record = Entrez.read(handle)\n",
      "        >>> handle.close()\n",
      "        >>> int(record[\"Count\"]) >= 2\n",
      "        True\n",
      "        >>> \"EF590893.1\" in record[\"IdList\"]\n",
      "        True\n",
      "        >>> \"EF590892.1\" in record[\"IdList\"]\n",
      "        True\n",
      "    \n",
      "    espell(**keywds)\n",
      "        Retrieve spelling suggestions as a results handle.\n",
      "        \n",
      "        ESpell retrieves spelling suggestions, if available.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESpell\n",
      "        \n",
      "        Return a handle to the results, by default in XML format.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> record = Entrez.read(Entrez.espell(term=\"biopythooon\"))\n",
      "        >>> print(record[\"Query\"])\n",
      "        biopythooon\n",
      "        >>> print(record[\"CorrectedQuery\"])\n",
      "        biopython\n",
      "    \n",
      "    esummary(**keywds)\n",
      "        Retrieve document summaries as a results handle.\n",
      "        \n",
      "        ESummary retrieves document summaries from a list of primary IDs or\n",
      "        from the user's environment.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESummary\n",
      "        \n",
      "        Return a handle to the results, by default in XML format.\n",
      "        \n",
      "        Raises an IOError exception if there's a network error.\n",
      "        \n",
      "        This example discovers more about entry 19923 in the structure\n",
      "        database:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.esummary(db=\"structure\", id=\"19923\")\n",
      "        >>> record = Entrez.read(handle)\n",
      "        >>> handle.close()\n",
      "        >>> print(record[0][\"Id\"])\n",
      "        19923\n",
      "        >>> print(record[0][\"PdbDescr\"])\n",
      "        Crystal Structure Of E. Coli Aconitase B\n",
      "    \n",
      "    parse(handle, validate=True, escape=False)\n",
      "        Parse an XML file from the NCBI Entrez Utilities into python objects.\n",
      "        \n",
      "        This function parses an XML file created by NCBI's Entrez Utilities,\n",
      "        returning a multilevel data structure of Python lists and dictionaries.\n",
      "        This function is suitable for XML files that (in Python) can be represented\n",
      "        as a list of individual records. Whereas 'read' reads the complete file\n",
      "        and returns a single Python list, 'parse' is a generator function that\n",
      "        returns the records one by one. This function is therefore particularly\n",
      "        useful for parsing large files.\n",
      "        \n",
      "        Most XML files returned by NCBI's Entrez Utilities can be parsed by\n",
      "        this function, provided its DTD is available. Biopython includes the\n",
      "        DTDs for most commonly used Entrez Utilities.\n",
      "        \n",
      "        The handle must be in binary mode. This allows the parser to detect the\n",
      "        encoding from the XML file, and to use it to convert all text in the XML\n",
      "        to the correct Unicode string. The functions in Bio.Entrez to access NCBI\n",
      "        Entrez will automatically return XML data in binary mode. For files,\n",
      "        please use mode \"rb\" when opening the file, as in\n",
      "        \n",
      "            >>> from Bio import Entrez\n",
      "            >>> handle = open(\"Entrez/pubmed1.xml\", \"rb\")  # opened in binary mode\n",
      "            >>> records = Entrez.parse(handle)\n",
      "            >>> for record in records:\n",
      "            ...     print(record['MedlineCitation']['Article']['Journal']['Title'])\n",
      "            ...\n",
      "            Social justice (San Francisco, Calif.)\n",
      "            Biochimica et biophysica acta\n",
      "            >>> handle.close()\n",
      "        \n",
      "        If validate is True (default), the parser will validate the XML file\n",
      "        against the DTD, and raise an error if the XML file contains tags that\n",
      "        are not represented in the DTD. If validate is False, the parser will\n",
      "        simply skip such tags.\n",
      "        \n",
      "        If escape is True, all characters that are not valid HTML are replaced\n",
      "        by HTML escape characters to guarantee that the returned strings are\n",
      "        valid HTML fragments. For example, a less-than sign (<) is replaced by\n",
      "        &lt;. If escape is False (default), the string is returned as is.\n",
      "        \n",
      "        Whereas the data structure seems to consist of generic Python lists,\n",
      "        dictionaries, strings, and so on, each of these is actually a class\n",
      "        derived from the base type. This allows us to store the attributes\n",
      "        (if any) of each element in a dictionary my_element.attributes, and\n",
      "        the tag name in my_element.tag.\n",
      "    \n",
      "    read(handle, validate=True, escape=False)\n",
      "        Parse an XML file from the NCBI Entrez Utilities into python objects.\n",
      "        \n",
      "        This function parses an XML file created by NCBI's Entrez Utilities,\n",
      "        returning a multilevel data structure of Python lists and dictionaries.\n",
      "        Most XML files returned by NCBI's Entrez Utilities can be parsed by\n",
      "        this function, provided its DTD is available. Biopython includes the\n",
      "        DTDs for most commonly used Entrez Utilities.\n",
      "        \n",
      "        The handle must be in binary mode. This allows the parser to detect the\n",
      "        encoding from the XML file, and to use it to convert all text in the XML\n",
      "        to the correct Unicode string. The functions in Bio.Entrez to access NCBI\n",
      "        Entrez will automatically return XML data in binary mode. For files,\n",
      "        please use mode \"rb\" when opening the file, as in\n",
      "        \n",
      "            >>> from Bio import Entrez\n",
      "            >>> handle = open(\"Entrez/esearch1.xml\", \"rb\")  # opened in binary mode\n",
      "            >>> record = Entrez.read(handle)\n",
      "            >>> print(record['QueryTranslation'])\n",
      "            biopython[All Fields]\n",
      "            >>> handle.close()\n",
      "        \n",
      "        If validate is True (default), the parser will validate the XML file\n",
      "        against the DTD, and raise an error if the XML file contains tags that\n",
      "        are not represented in the DTD. If validate is False, the parser will\n",
      "        simply skip such tags.\n",
      "        \n",
      "        If escape is True, all characters that are not valid HTML are replaced\n",
      "        by HTML escape characters to guarantee that the returned strings are\n",
      "        valid HTML fragments. For example, a less-than sign (<) is replaced by\n",
      "        &lt;. If escape is False (default), the string is returned as is.\n",
      "        \n",
      "        Whereas the data structure seems to consist of generic Python lists,\n",
      "        dictionaries, strings, and so on, each of these is actually a class\n",
      "        derived from the base type. This allows us to store the attributes\n",
      "        (if any) of each element in a dictionary my_element.attributes, and\n",
      "        the tag name in my_element.tag.\n",
      "\n",
      "DATA\n",
      "    api_key = None\n",
      "    email = None\n",
      "    max_tries = 3\n",
      "    sleep_between_tries = 15\n",
      "    tool = 'biopython'\n",
      "\n",
      "FILE\n",
      "    /home/ylee/.conda/envs/py_env/lib/python3.8/site-packages/Bio/Entrez/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Entrez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d321b9-a926-4082-b260-7fc6ab4f721b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: NM_009609.3\n",
      "Name: NM_009609\n",
      "Description: Mus musculus actin, gamma, cytoplasmic 1 (Actg1), transcript variant 1, mRNA\n",
      "Annotations: {'molecule_type': 'mRNA', 'topology': 'linear', 'data_file_division': 'ROD', 'date': '30-APR-2024', 'accessions': ['NM_009609', 'NM_013798', 'XM_193346'], 'sequence_version': 3, 'keywords': ['RefSeq', 'RefSeq Select'], 'source': 'Mus musculus (house mouse)', 'organism': 'Mus musculus', 'taxonomy': ['Eukaryota', 'Metazoa', 'Chordata', 'Craniata', 'Vertebrata', 'Euteleostomi', 'Mammalia', 'Eutheria', 'Euarchontoglires', 'Glires', 'Rodentia', 'Myomorpha', 'Muroidea', 'Muridae', 'Murinae', 'Mus', 'Mus'], 'references': [Reference(title='Genetic determinants of micronucleus formation in vivo', ...), Reference(title='Spatial transcriptomics reveals novel genes during the remodelling of the embryonic human arterial valves', ...), Reference(title='Transgenerational epigenetic effects imposed by neonicotinoid thiacloprid exposure', ...), Reference(title='Genome-wide analysis of sex-specific differences in the mother-child PELAGIE cohort exposed to organophosphate metabolites', ...), Reference(title='Validation of superior reference genes in mouse submandibular glands under developmental and functional regeneration states', ...), Reference(title='High level expression of transfected beta- and gamma-actin genes differentially impacts on myoblast cytoarchitecture', ...), Reference(title='Identification and developmental expression of a smooth-muscle gamma-actin in postmeiotic male germ cells of mice', ...), Reference(title='Mouse cytoskeletal gamma-actin: analysis and implications of the structure of cloned cDNA and processed pseudogenes', ...), Reference(title='Regulation of amyloid A gene expression in cultured cells', ...), Reference(title='Actin amino-acid sequences. Comparison of actins from calf thymus, bovine brain, and SV40-transformed mouse 3T3 cells with rabbit skeletal muscle actin', ...)], 'comment': \"REVIEWED REFSEQ: This record has been curated by NCBI staff. The\\nreference sequence was derived from AK153446.1 and CX567990.1.\\nOn Sep 11, 2015 this sequence version replaced NM_009609.2.\\nSummary: Actins are highly conserved proteins that are involved in\\nvarious types of cell motility and maintenance of the cytoskeleton.\\nIn vertebrates, three main groups of actin isoforms, alpha, beta,\\nand gamma, have been identified. The alpha actins are found in\\nmuscle tissues and are a major constituent of the contractile\\napparatus. The beta and gamma actins co-exist in most cell types as\\ncomponents of the cytoskeleton, and as mediators of internal cell\\nmotility. Actin, gamma 1, encoded by this gene, is a cytoplasmic\\nactin found in non-muscle cells. Alternative splicing results in\\nmultiple transcript variants. [provided by RefSeq, Sep 2015].\\nTranscript Variant: This variant (1) encodes the longer isoform\\n(1).\\nPublication Note:  This RefSeq record includes a subset of the\\npublications that are available for this gene. Please see the Gene\\nrecord to access additional publications.\\nCOMPLETENESS: complete on the 3' end.\", 'structured_comment': OrderedDict([('Evidence-Data', OrderedDict([('Transcript exon combination', 'AK153446.1, AF195094.1 [ECO:0000332]'), ('RNAseq introns', 'mixed sample support SAMN00849374, SAMN00849375 [ECO:0006172]')])), ('RefSeq-Attributes', OrderedDict([('RefSeq Select criteria', 'based on conservation, expression, longest protein')]))])}\n",
      "Sequence: GGTCTCACACTCCGCCGCCGGCTTACACTGCGCTTCTTGCCGCTCCTCCGTCGCCGCCGCGTCCTTCGCCGATCGCAATGGAAGAAGAAATCGCCGCACTCGTCATTGACAATGGCTCCGGCATGTGCAAAGCCGGCTTTGCTGGCGACGACGCCCCCAGGGCCGTGTTCCCTTCCATCGTAGGGCGCCCCCGACACCAGGGCGTCATGGTGGGCATGGGCCAGAAAGACTCATACGTGGGTGACGAGGCCCAGAGCAAGAGGGGTATCCTGACCCTGAAGTACCCTATCGAACACGGCATTGTCACTAACTGGGACGACATGGAGAAGATCTGGCACCACACCTTCTACAATGAGCTGCGTGTGGCTCCTGAGGAGCACCCGGTGCTTCTGACCGAGGCCCCCCTGAACCCCAAAGCTAACAGAGAGAAGATGACGCAGATAATGTTTGAAACCTTCAATACCCCAGCCATGTACGTGGCCATTCAGGCGGTGCTGTCCTTGTATGCATCTGGGCGCACCACTGGCATTGTCATGGACTCTGGTGACGGGGTCACACACACAGTGCCCATCTATGAGGGCTACGCCCTTCCCCACGCCATCTTGCGTCTGGACCTGGCTGGCCGGGACCTGACAGACTACCTCATGAAGATCCTGACTGAACGGGGCTACAGCTTTACCACCACTGCTGAGAGGGAAATTGTTCGTGACATAAAGGAGAAGCTGTGCTATGTTGCCCTGGATTTTGAGCAAGAAATGGCTACTGCTGCATCATCTTCCTCCTTGGAGAAGAGTTACGAGCTGCCCGACGGGCAGGTGATCACCATTGGCAATGAGCGGTTCCGGTGTCCGGAGGCACTCTTCCAGCCTTCCTTCCTGGGCATGGAGTCCTGTGGTATCCATGAGACCACTTTCAACTCCATCATGAAGTGTGATGTGGATATCCGCAAAGACCTGTATGCCAATACAGTGCTGTCTGGTGGTACCACCATGTACCCAGGCATTGCTGACAGGATGCAGAAGGAGATCACAGCCCTAGCACCTAGCACGATGAAGATTAAGATCATTGCTCCCCCTGAGCGCAAGTACTCAGTCTGGATCGGTGGCTCCATTCTGGCCTCACTGTCCACCTTCCAGCAGATGTGGATCAGCAAGCAGGAGTATGATGAGTCAGGCCCCTCCATCGTCCACCGCAAATGCTTCTAGATGGACTGAGCAGGTGCCAGGCATCTGCTGCATGAGCTGATATTGAAGTATCAATTTGCCCTGGCAAATGTACACACCTCATGCTAGCCTCATGAAACTGGAATAAGCCTTTGAAAAGAAATTTGTCCTTGAAGCTTGTATCTGATATCAGCACTGGATCGTAGAACTTGTTGCTGATTTTTGACCTTGTATTCAAGTTAACTGCTCCCTTGGTATATGTTTAATACCCTGTGCATATCTTGATTTAGTCCTTAGTTCATGTGGCTCGGTCACTTGGGGGCTGGGGAGAGCACGCTGTAGATGAGAAAGCCCCAGCCTGGTGGATCTCTGTGAGCACCACTGAGTGATCTGTGCAGGGTATTAACCAACAGCAGACTTCCAGGATTTCCTGAGGCTGGCAAGGGTTCCTGAACCAGTTACCACTCCTTCTTGCCAGTCTAACAGGGTGGGAAAGTCCGAGCCTTAGGACCCAGTTTCAGTTCTGGTTTCTTCCCTCCTGACCACCATCGGTTGTTAGTTGCCTTGAGTTGGGAACGTTTGCATCGACACCTGTAAATGTATTCATTCTTTAATTTATGTAAGGTTTTTTGTACTCAATTCTTTAAGAAATGACAAATTTTGGTTTTCTACTGTTCAATGAGAACATTAGGCCCCAGCAACACGTCATTGTGTAAAGAAATAAAAGTGCTGCAGTAACTGACCAAAAAAAAAAAAA\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Path to your .gb file\n",
    "file_path = \"/home/ylee/blast/blastdb/NM_009609.gb\"\n",
    "\n",
    "# Parse the GenBank file\n",
    "with open(file_path, \"r\") as file:\n",
    "    record = SeqIO.read(file, \"genbank\")\n",
    "\n",
    "# Display basic information\n",
    "print(f\"ID: {record.id}\")\n",
    "print(f\"Name: {record.name}\")\n",
    "print(f\"Description: {record.description}\")\n",
    "print(f\"Annotations: {record.annotations}\")\n",
    "print(f\"Sequence: {record.seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6931ab9-18e0-4e7d-b5e5-d023218795ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download seq from UCSC (api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058827aa-dbd1-4360-ae6d-a115b28ae2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### download nucleotide sequence from UCSC Genome Browser via TOGAWS API, in FASTA format\n",
    "\n",
    "def ucsc_downloader(chr_id, start, end, specie='mouse'):\n",
    "    species_dict = {'human':'hg38', 'mouse':'mm10', 'worm':'ce6', \n",
    "                    'fish':'danRer11'}\n",
    "    spec = species_dict[specie]\n",
    "    url = f'http://togows.org/api/ucsc/{spec}/chr{chr_id}:{start}-{end}.fasta'\n",
    "    response = requests.get(url)\n",
    "    sequence = fasta_reader(response.text)\n",
    "    return sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae897a-5aa8-4358-883c-17cd41a54a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucsc_downloader(chr_id, start, end, specie='mouse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15befc-c6c3-48c9-acb3-4bcd53b3208f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sequence processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f63b7-29d7-42ff-ae09-49fbc5dcc420",
   "metadata": {},
   "outputs": [],
   "source": [
    "### process FASTA and extract sequence, removing the formatting lines\n",
    "\n",
    "def fasta_reader(text):     # input string containing FASTA formatted sequence\n",
    "    ind = text.find('\\n')\n",
    "    pre_seq = text[ind:]\n",
    "    real_seq = pre_seq.replace('\\n', '')\n",
    "    return real_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b08ef-ccd4-457f-9007-710a8c8f4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### retrieve protein-coding transcripts for a given gene from a genomic dataset\n",
    "\n",
    "def get_protein_coding_transcripts(genome, gene_id):\n",
    "    gene = genome.gene_by_id(gene_id)\n",
    "    protein_coding_transcripts = []\n",
    "    for transcript in gene.transcripts:\n",
    "        if transcript.biotype == 'protein_coding':\n",
    "            protein_coding_transcripts.append(transcript)\n",
    "    return protein_coding_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4252cc-0db0-480d-a397-994dc2800da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_intron_length(genome, gene_id):\n",
    "    gene = genome.gene_by_id(gene_id)\n",
    "    transcripts = get_protein_coding_transcripts(gene_id)\n",
    "    \n",
    "    length_to_first_intron_end = 0    \n",
    "    length_of_five_prime_utr = 0\n",
    "    distance_to_gene_start = 0\n",
    "    for transcript in transcripts:\n",
    "        if gene.strand == '-':\n",
    "            try:\n",
    "                distance_to_gene_start_intron = gene.end - transcript.end\n",
    "                first_exon_intron = transcript.exon_intervals[0][1] - transcript.exon_intervals[1][1]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                distance_to_gene_start = gene.end - transcript.start_codon_positions[-1]\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                distance_to_gene_start_intron = transcript.start - gene.start\n",
    "                first_exon_intron = transcript.exon_intervals[1][0] - transcript.exon_intervals[0][0]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                distance_to_gene_start = transcript.start_codon_positions[0] - gene.start \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if distance_to_gene_start_intron + first_exon_intron >length_to_first_intron_end:\n",
    "            length_to_first_intron_end = distance_to_gene_start_intron + first_exon_intron\n",
    "        if distance_to_gene_start >length_of_five_prime_utr:\n",
    "            length_of_five_prime_utr = distance_to_gene_start\n",
    "        \n",
    "    return length_to_first_intron_end, length_of_five_prime_utr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c6deb-7681-4097-a256-02585c421ef0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download seq from wormbase(wormbase_parasite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424d477-de53-4f4c-9c67-6020dae33985",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def worm_transcript_seq(transcript_id, spliced=False, annotation=False):\n",
    "    if spliced == True:\n",
    "        which = 'spliced_sequence_context'\n",
    "    else:\n",
    "        which = 'unspliced_sequence_context'\n",
    "        \n",
    "    response = requests.get(f\"http://rest.wormbase.org/rest/widget/transcript/{transcript_id}/sequences\")\n",
    "    j = response.json() \n",
    "\n",
    "    data_str = json.dumps(j)\n",
    "    data = json.loads(data_str)\n",
    "    if data['fields']['strand']['data'] == '-':\n",
    "        strand = 'negative_strand'\n",
    "    else:\n",
    "        strand = 'positive_strand'\n",
    "    \n",
    "    transcript_seq = data['fields'][which]['data'][strand]['sequence']\n",
    "    \n",
    "    if annotation==False:\n",
    "        return transcript_seq\n",
    "    else:\n",
    "        return data['fields'][which]['data'][strand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba0da9-2188-4574-8255-183f8531903e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def import_worm_genome(filename='data/caenorhabditis_elegans.PRJNA13758.WBPS17.genomic.fa'):\n",
    "    chromosome_dict = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        n = 0\n",
    "        string = ''\n",
    "        for line in lines: \n",
    "            if line.startswith('>'):\n",
    "                if string != '':\n",
    "                    chromosome_dict[chr_] = string\n",
    "                chr_ = line[1:].strip()\n",
    "                n = 1 \n",
    "                string = ''\n",
    "            elif n == 1:\n",
    "                string += line.strip()\n",
    "        chromosome_dict[chr_] = string \n",
    "    return chromosome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605bba0-932a-4f63-a125-8eaaf6b06e6c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def worm_genome_seq(chr_, start, end, strand):\n",
    "    try:\n",
    "        api = wormbase_parasite.WormbaseClient()\n",
    "        inquiry = f'{chr_}:{start}:{end}:{strand}'\n",
    "        seq = api.get_sequence_for_region(inquiry, 'c.elegans')['seq']\n",
    "    except:\n",
    "        print('local')\n",
    "        filename = [i for i in os.listdir('input/') if i.endswith('.fa')][0]\n",
    "        chromosome_dict = import_worm_genome('input/'+filename)\n",
    "        if strand!='-1':\n",
    "            seq = chromosome_dict[chr_][start+2:end+3]\n",
    "        else:\n",
    "            seq = str(Seq(chromosome_dict[chr_][start+2:end+3]).reverse_complement())\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d3a7b-c847-4f02-99ac-efacb6c185ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def worm_get_DNA_seq(gene_id, upstream=0, downstream=0):\n",
    "    response = requests.get(f\"http://rest.wormbase.org/rest/widget/gene/{gene_id}/sequences\")\n",
    "    j = response.json() \n",
    "\n",
    "    data_str = json.dumps(j)\n",
    "    data = json.loads(data_str)\n",
    "    try:\n",
    "        transcript_id = data['fields']['gene_models']['data']['table'][0]['model'][0]['id']\n",
    "    except:\n",
    "        transcript_id = data['fields']['gene_models']['data']['table'][0]['model']['id']\n",
    "    \n",
    "    response = requests.get(f\"http://rest.wormbase.org/rest/widget/transcript/{transcript_id}/sequences\")\n",
    "    j = response.json() \n",
    "\n",
    "    data_str = json.dumps(j)\n",
    "    data = json.loads(data_str)\n",
    "\n",
    "    if data['fields']['strand']['data'] == '-':\n",
    "        strand = '-1'\n",
    "    else:\n",
    "        strand = '1'\n",
    "\n",
    "    response = requests.get(f\"http://rest.wormbase.org/rest/widget/gene/{gene_id}/location\")\n",
    "    j = response.json() \n",
    "\n",
    "    data_str = json.dumps(j)\n",
    "    data = json.loads(data_str)\n",
    "    location = data['fields']['genomic_position']['data'][0]['label']\n",
    "    chr_ = location.split(':')[0]\n",
    "    if strand == '-1':\n",
    "        start = int(location.split(':')[1].split('..')[0]) - downstream\n",
    "        end = int(location.split(':')[1].split('..')[1]) + upstream\n",
    "    else:\n",
    "        start = int(location.split(':')[1].split('..')[0]) - upstream\n",
    "        end = int(location.split(':')[1].split('..')[1]) + downstream     \n",
    "    \n",
    "    #gene_length = abs(int(location.split(':')[1].split('..')[0])-int(location.split(':')[1].split('..')[1]))\n",
    "    seq = worm_genome_seq(chr_, start, end, strand) \n",
    "    return seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.8.13",
   "language": "python",
   "name": "py_3.8.13."
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
